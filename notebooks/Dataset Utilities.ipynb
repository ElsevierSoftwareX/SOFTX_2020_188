{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Utilities\n",
    "\n",
    "In the following notebook we will demonstrate several utilities provided by RankEval in working and manipulating a Dataset in the SVMLight format. In particular, how to:\n",
    " - Easily Load standard LtR datasets as well as several pre-trained models\n",
    " - Fork a dataset by selecting only a subset of the features\n",
    " - Fork a dataset by selecting only some queries\n",
    " - Dump a dataset on file in the SVMLight format\n",
    " - Split a dataset in train, validation (eventually) and test sets\n",
    " - Manually accessing low level dataset information\n",
    " - Iterate over each query of a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Essential imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Useful to reload the module without having to restart the notebook kernel\n",
    "from rankeval.dataset.datasets_fetcher import load_dataset\n",
    "from rankeval.dataset import Dataset\n",
    "from rankeval.model import RTEnsemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading datasets and models\n",
    "\n",
    "Standard LtR datasets can be easily loaded by calling the load_dataset utility. This tool allows to load datasets and several pre-trained models from a central repository, in such a way to simplify the setting of the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files. This may take a few minutes.\n",
      "done loading dataset!\n"
     ]
    }
   ],
   "source": [
    "# Dataset container\n",
    "dataset_container = load_dataset(dataset_name='msn10k', \n",
    "                                fold='1', \n",
    "                                download_if_missing=True, \n",
    "                                force_download=False,\n",
    "                                with_models=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remapping Datasets Names\n",
    "msn_train = dataset_container.train_dataset\n",
    "msn_validation = dataset_container.validation_dataset\n",
    "msn_test = dataset_container.test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose and load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /Users/salvatore/rankeval_data/msn10k/models/Fold1/quickrank/msn1.quickrank.LAMBDAMART.20000.32.T15000.xml\n",
      "1 /Users/salvatore/rankeval_data/msn10k/models/Fold1/quickrank/msn1.quickrank.LAMBDAMART.20000.32.T5000.xml\n",
      "2 /Users/salvatore/rankeval_data/msn10k/models/Fold1/quickrank/msn1.quickrank.LAMBDAMART.20000.32.T20000.xml\n",
      "3 /Users/salvatore/rankeval_data/msn10k/models/Fold1/quickrank/msn1.quickrank.LAMBDAMART.20000.32.T10000.xml\n",
      "4 /Users/salvatore/rankeval_data/msn10k/models/Fold1/quickrank/msn1.quickrank.LAMBDAMART.20000.32.T1000.xml\n",
      "5 /Users/salvatore/rankeval_data/msn10k/models/Fold1/xgboost/XGBOOST.msn10k.fold-1.pairwise.d-5.lr-10.trees-1000.model\n",
      "6 /Users/salvatore/rankeval_data/msn10k/models/Fold1/lightgbm/LGBM.msn10k.fold-1.lambdarank.leaves-32.lr-5.trees-1000.model\n",
      "7 /Users/salvatore/rankeval_data/msn10k/models/Fold1/catboost/msn1.catboost.LAMBDAMART.1000.5.T1000.json\n",
      "8 /Users/salvatore/rankeval_data/msn10k/models/Fold1/catboost/msn1.catboost.LAMBDAMART.1000.5.T1000.model\n"
     ]
    }
   ],
   "source": [
    "# View available models\n",
    "for item, file_name in enumerate(dataset_container.model_filenames):\n",
    "    print (item, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model files\n",
    "msn_qr_lmart_1Ktrees_file = dataset_container.model_filenames[4]\n",
    "# Loading model into RankEval\n",
    "msn_qr_lmart_1Ktrees = RTEnsemble(msn_qr_lmart_1Ktrees_file, name=\"QR_lmart_1K\", format=\"QuickRank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fork a dataset by selecting only a subset of the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from a dataset, it is possible to create a new dataset instance with only a subset of the features appearing in the original dataset. \n",
    "This feature is particularly useful when the task is to analyze the feature importance, trying to reduce as much as possible the features needed by a LtR model without affecting the quality of the learned model. \n",
    "An example of such analysis is reported in the notebook: [Feature Analysis](Feature%20Analysis.ipynb).\n",
    "\n",
    "In this notebook the features selected will be the 20% of all the features, randomly choosen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_permutation = np.random.permutation(msn_train.n_features)\n",
    "selected_features = feature_permutation[:int(msn_train.n_features*0.2)]\n",
    "\n",
    "msn_train_subset_features = msn_train.subset_features(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Queries</th>\n",
       "      <th># Instances</th>\n",
       "      <th># Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Full</th>\n",
       "      <td>6000</td>\n",
       "      <td>723412</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sampled by Feature</th>\n",
       "      <td>6000</td>\n",
       "      <td>723412</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    # Queries  # Instances  # Features\n",
       "Full                     6000       723412         136\n",
       "Sampled by Feature       6000       723412          27"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'# Queries': [msn_train.n_queries, msn_train_subset_features.n_queries], \n",
    "     '# Instances': [msn_train.n_instances, msn_train_subset_features.n_instances], \n",
    "     '# Features': [msn_train.n_features, msn_train_subset_features.n_features],}\n",
    "df = pd.DataFrame(data=d, index=[\"Full\", \"Sampled by Feature\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the models have to be used only in consistent conditions, i.e., if you train a model on this sampled dataset also the test dataset (and eventually the validation) has to be changed accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "msn_test_subset_features = msn_test.subset_features(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fork a dataset by selecting only a subset of the queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from a dataset, it is possible to create a new dataset instance by selecting only some of the queries of the original dataset. The query to select are identified by qid (query id).\n",
    "\n",
    "In this notebook we select only 20% of all the queries, randomly choosen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "qid_permutation = np.random.permutation(msn_train.query_ids)\n",
    "selected_qid = qid_permutation[:int(msn_train.query_ids.size*0.2)]\n",
    "\n",
    "msn_train_subset_queries = msn_train.subset(query_ids=selected_qid, name=\"MSN Train Fold1 - 20% of the queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Queries</th>\n",
       "      <th># Instances</th>\n",
       "      <th># Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Full</th>\n",
       "      <td>6000</td>\n",
       "      <td>723412</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sampled by Query</th>\n",
       "      <td>1200</td>\n",
       "      <td>145114</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  # Queries  # Instances  # Features\n",
       "Full                   6000       723412         136\n",
       "Sampled by Query       1200       145114         136"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'# Queries': [msn_train.n_queries, msn_train_subset_queries.n_queries], \n",
    "     '# Instances': [msn_train.n_instances, msn_train_subset_queries.n_instances], \n",
    "     '# Features': [msn_train.n_features, msn_train_subset_queries.n_features],}\n",
    "df = pd.DataFrame(data=d, index=[\"Full\", \"Sampled by Query\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dump a model on file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you modify a dataset (by selecting only a subset of the queries or of the features) you can save the modified version on file in the standard SVMLight format. This operation is provided by RankEval to simplify the activity of manipulating and working on LtR datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_file = \"msn_fold1_27_random_features.txt\"\n",
    "msn_train_subset_features.dump(destination_file, format=\"svmlight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the top 10 lines of the file where the dataset has been written into (and delete it):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 qid:1 1:0 2:1 3:0.011976 4:0 5:5.9924598 6:0 7:16.76696 8:2.2971971 9:0 10:0 11:-21.339609 12:0 13:6.1565952 14:13 15:167 16:1 17:0.011976 18:12.941469 19:0.019231001 20:0 21:6.9265509 22:3.078917 23:0 24:0.0064099999 25:0 26:2 27:0 \n",
      "2 qid:1 1:0 2:0 3:0.021635 4:0.88888901 5:0 6:0.88888901 7:21.161667 8:12.634581 9:0.60000002 10:0 11:-24.805464 12:7.9857841 13:33.861275 14:1 15:416 16:0 17:0.026442001 18:20.885118 19:0.068966001 20:0 21:6.9265509 22:30.789171 23:0 24:0.024630999 25:0 26:10.333333 27:0 \n",
      "0 qid:1 1:0 2:0 3:0.0064099999 4:6.8888888 5:0 6:9.5555563 7:18.279205 8:2.6996551 9:0.66666698 10:0 11:-24.805464 12:6.3144059 13:21.548082 14:14 15:156 16:0 17:0.051282 18:18.140879 19:0.09589 20:0 21:6.9265509 22:18.473503 23:0 24:0.047945 25:0 26:5.333333 27:0.024691001 \n",
      "2 qid:1 1:0 2:0 3:0.010033 4:0.222222 5:0 6:0.222222 7:17.53163 8:4.5943928 9:0.75 10:0 11:-24.805464 12:7.9857841 13:9.2348928 14:1 15:299 16:0 17:0.013378 18:15.572998 19:0.024390001 20:0 21:6.9265509 22:6.1578341 23:0 24:0.010453 25:0 26:3.333333 27:0 \n",
      "1 qid:1 1:0 2:0 3:0.001484 4:0.222222 5:0 6:0.222222 7:9.7497072 8:4.5943928 9:0.75 10:0 11:-24.805464 12:7.9857841 13:10.798622 14:1 15:2022 16:0 17:0.0019779999 18:7.802556 19:0.0039820001 20:0 21:6.9265509 22:8.100687 23:0 24:0.001493 25:0 26:3.666667 27:0 \n",
      "1 qid:1 1:0 2:0 3:0.0031610001 4:14.888889 5:0 6:14.888889 7:16.692247 8:8.0989656 9:0.75 10:0 11:-24.805464 12:7.9857841 13:30.782976 14:5 15:949 16:0 17:0.012645 18:15.468397 19:0.023529001 20:0 21:6.9265509 22:27.710255 23:0 24:0.011765 25:0 26:8.333333 27:0 \n",
      "1 qid:1 1:0 2:0 3:0.002177 4:14.222222 5:0 6:14.222222 7:15.256367 8:8.0989656 9:0.75 10:0 11:-24.805464 12:7.9857841 13:33.861275 14:3 15:1378 16:0 17:0.007983 18:14.026719 19:0.016140999 20:0 21:6.9265509 22:30.789171 23:0 24:0.0073370002 25:0 26:8.333333 27:0 \n",
      "2 qid:1 1:0 2:0 3:0.0099400003 4:76.222221 5:0 6:76.222221 7:20.870281 8:13.498277 9:0.75 10:0 11:-24.805464 12:7.9857841 13:70.800842 14:1 15:503 16:0 17:0.047713999 18:20.435484 19:0.100204 20:0 21:6.9265509 22:67.736176 23:0 24:0.047035001 25:0 26:17.333332 27:0 \n",
      "1 qid:1 1:0 2:0 3:0.003058 4:2.666667 5:0 6:2.666667 7:14.530013 8:9.1887856 9:0.75 10:0 11:-24.805464 12:7.9857841 13:18.469786 14:1 15:1308 16:0 17:0.006116 18:13.208906 19:0.011583 20:0 21:6.9265509 22:15.394586 23:0 24:0.0054049999 25:0 26:6 27:0 \n",
      "0 qid:1 1:0 2:0 3:0.0096340002 4:76.222221 5:0 6:76.222221 7:20.810034 8:13.498277 9:0.75 10:0 11:-24.805464 12:7.9857841 13:70.800842 14:1 15:519 16:0 17:0.046243001 18:20.347855 19:0.096078001 20:0 21:6.9265509 22:67.736176 23:0 24:0.045097999 25:0 26:17.333332 27:0 \n"
     ]
    }
   ],
   "source": [
    "!head -10 $destination_file\n",
    "!rm $destination_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split a dataset in train, validation (eventually) and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is common the need to split a LtR dataset in train, validation and test sets as to train a LtR model and test its effectiveness on a different split.\n",
    "Rankeval provides an utility to split a dataset into partitions. It shuffle the query ids before partitioning.\n",
    "\n",
    "In this notebook for simplicity we split the training set of the MSN-Fold1 dataset according to the 60%/20%/20% ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, vali, test = msn_train.split(train_size=0.6, vali_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Queries</th>\n",
       "      <th># Instances</th>\n",
       "      <th># Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>3600</td>\n",
       "      <td>432458</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vali</th>\n",
       "      <td>1200</td>\n",
       "      <td>144283</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>1200</td>\n",
       "      <td>146671</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       # Queries  # Instances  # Features\n",
       "Train       3600       432458         136\n",
       "Vali        1200       144283         136\n",
       "Test        1200       146671         136"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'# Queries': [train.n_queries, vali.n_queries, test.n_queries], \n",
    "     '# Instances': [train.n_instances, vali.n_instances, test.n_instances], \n",
    "     '# Features': [train.n_features, vali.n_features, test.n_features],}\n",
    "df = pd.DataFrame(data=d, index=[\"Train\", \"Vali\", \"Test\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `vali_size` is set to 0, the method will skip the creation of a validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing low-level information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset class provides an interface storing dataset information and providing utilities for easily accessing it. In some situation however it is needed to access the low level information there stored. In this notebook, we describe how this information is stored, and how to iterate over the queries of a dataset accessing features, labels and query ids in order.\n",
    "\n",
    "We start by describing the base component of a dataset instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This are the main charateristics of the dataset we are adopting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Queries</th>\n",
       "      <th># Instances</th>\n",
       "      <th># Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <td>6000</td>\n",
       "      <td>723412</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         # Queries  # Instances  # Features\n",
       "Dataset       6000       723412         136"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'# Queries': [msn_train.n_queries], \n",
    "     '# Instances': [msn_train.n_instances], \n",
    "     '# Features': [msn_train.n_features],}\n",
    "df = pd.DataFrame(data=d, index=[\"Dataset\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each dataset is described in primis by the feature matrix (numpy 2d array) of its feature. The rows of this matrix are the instances, whether the columns are the features. The shape of the matrix is thus (n_instances, n_features):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(723412, 136)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msn_train.X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each cell of this matrix identify the value of a single feature/document pair. For example, the value of the 10-th feature of the 5-th instance is (remember indices starts from 0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msn_train.X[4, 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ground truth labels are stored in a separate vector (numpy 1d array), with a single value for each dataset instance. The shape of the vector is thus (n_instances):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(723412,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msn_train.y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each cell of this vector identify the ground truth value of a single instance for the specific query. For example, the ground truth value of the 5-th instance is (recall ground truth labels usually range in [0-4], with 0 meaning completely irrelevant and 4 perfectly relevant):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msn_train.y[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The query ids of the dataset are stored in a separate vector. This information is not strictly needed, but when you manipulate a dataset sometime it is important to preserve this information (e.g., for comparison).\n",
    "This information is stored in a vector (numpy 1d array) with a single value for each dataset query. The shape of the vector is thus (n_queries):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msn_train.query_ids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The query id of the first query is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msn_train.query_ids[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The offsets of each query are on the other hand stored in another vector (numpy 1d array). These offsets allows to associate each dataset instance to the correct query. Recall indeed that both features and ground truth labels are stored contiguosly between several queries, thus it is needed a mechanism allowing to discriminate and reconstruct the information regarding each query.\n",
    "\n",
    "This array stores the starting offset of each query (starting from the first instance identified by the first row). Its shape is thus (n_queries+1), with the latter element that is not strictly needed but is put there for simplicity (its value is always the number of instances in the dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6001,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msn_train.query_offsets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given this information, the i-th query has indices ranging from query_offsets[i] up to query_offsets[i+1], with the latter element excluded. For example, the first query start at index 0 and contains 86 documents up to index 86 (excluded):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 86])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msn_train.query_offsets[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of documents in each query can thus be obtained automatically from the `query_offset` variable. However, RankEval provide a simple utility for accessing this information, that is the `get_query_sizes` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 86, 106,  92, ...,  79, 180,  40])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msn_train.get_query_sizes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method returns a vector (numpy 1d array) with a single element for each query, identifying the number of documents belonging to this query. As noticed above, the first query has 86 documents, the second has 106 documents, and so on and so forth. The shape of this vector is thus (n_queries):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msn_train.get_query_sizes().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some situation we need to have the list of query ids, one for each instance (in place of the compact version adopted by RankEval). For example, this feature is needed by LightGBM when you need to create a dataset. RankEval provides such information with the `get_qids_dataset` utility, returning a vector (numpy 1d array) with shape (n_instances):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(723412,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msn_train.get_qids_dataset().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first document has qid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msn_train.get_qids_dataset()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate over each query of a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometime it is needed to iterate over the low level information stored in the dataset instance. RankEval allows you to do that with the `query_iterator` utility, that provides you with an iterator over the offsets of the query_ids in the dataset. In particular, each element of the iterator is a tuple (qid, start_offset, end_offset), highlighting thus the qid of the query and the row index of the instances belonging it. For example, the first element of the iterator is related to the query with `qid=1` and offset ranging from 0 to 86 (excluded):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0, 86)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(msn_train.query_iterator())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
