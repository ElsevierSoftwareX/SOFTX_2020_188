{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias-Variance\n",
    "\n",
    "... on going ...\n",
    "\n",
    "by reading a few papers [cite] the methodology is as follows...\n",
    "\n",
    "The Loss of a Algorithm (not of a model!) can be decomposed in:\n",
    "$$L(A) = Bias(A) + Variance(A) + Noise(A)$$\n",
    "where:\n",
    " - Bias is how far is the model from the prediction\n",
    " - Variance is how sensitive (how changes) the prediction with different training sets (overfitting)\n",
    " - Noise is the irreducible error in the dataset (learner independent)\n",
    "\n",
    "Given a dataset $D$, given a number of iteration $l$, we need to produce $l$ score predictions\n",
    "for each element in $D$ with $l$ different models. If the loss function $L$ is MSE then everything is clear.\n",
    "If the loss function is NDCG, no previous work.\n",
    "\n",
    "  0. Shuffle $D$ and create two halves $D_1$ and $D_2$ (this should be query-aware with NDCG)\n",
    "  0. learn a model from $D_1$ and apply it to $D_2$\n",
    "  0. learn a model from $D_2$ and apply it to $D_1$\n",
    "  0. store the scores produced so far\n",
    "  0. Repeat all of the above $l$ times\n",
    "  0. for each document/query compute the average prediction by averagin the $l$ stored so far (for ranking this is actually not defined, we may average predictions and then rank accordingly)\n",
    "  0. Bias of a query/document is computed as the loss between the ideal prediction and the average prediction\n",
    "  0. Average above for every query/document to obtain final Bias\n",
    "  0. Variance of a query/document is computed as the average loss between the average prediction and every of the $l$ predictions\n",
    "  0. Average above for every query/document to obtain final Variance\n",
    " \n",
    "Usually Noise is assumed to be 0 as it is impossible to estimated it.\n",
    "As a consequence, ometimes Variance is defined as $L(A)-Bias(A)$.\n",
    "\n",
    "In every work, $L(A)$ should be equal to $Bias(A) + Variance(A)$. Is this true for NDCG? probably not ...\n",
    "\n",
    "In principle, we may provide just the Loss and the Bias, and let the user compute variance by difference.\n",
    "\n",
    "We might probalby solve the ranking problem, by saying that L is not 1-NDCG, but rather (1-NDCG)^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rankeval.core.dataset import Dataset\n",
    "import numpy as np\n",
    "import lightgbm\n",
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = Dataset.load(\"/Users/claudio/docs/LAVORO/coding/ltr/QuickScorer/debug_data/msn1.fold1.test.5k.txt\", name=\"msn1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_algo(train_X, train_Y, train_q, test_X):\n",
    "    params = {'num_leaves': 2, 'objective':'lambdarank',\n",
    "             'learning_rate': 0.01, 'max_bin': 1024}\n",
    "\n",
    "    training = lightgbm.Dataset(data=train_X, label=train_Y, group=train_q)\n",
    "    \n",
    "    bst = lightgbm.train(params, training, num_boost_round=100)\n",
    "    \n",
    "    # check the number of trees and other params is correct\n",
    "    # print ( len(bst.dump_model()[u'tree_info']) )\n",
    "    \n",
    "    return bst.predict(test_X)\n",
    "\n",
    "\n",
    "def kfold_scoring(dataset, k, algo):\n",
    "    scores = np.zeros(dataset.n_instances, dtype=np.float32)\n",
    "    q_lens = dataset.query_ids[1:]-dataset.query_ids[:-1]\n",
    "    partition_ids = np.random.randint(k, size=dataset.n_queries)\n",
    "    for p in range(k):\n",
    "        print (\" - Processing fold\", p, \"of\", k)\n",
    "        test_rows = np.zeros(dataset.n_instances, dtype=np.bool)\n",
    "        for q in np.where(partition_ids==p)[0]:\n",
    "            test_rows[ dataset.query_ids[q]:dataset.query_ids[q+1] ] = True\n",
    "        train_rows = np.logical_not(test_rows)\n",
    "        \n",
    "        fold_scores = algo(dataset.X[train_rows], dataset.y[train_rows], q_lens[partition_ids!=p],\n",
    "                           dataset.X[test_rows])\n",
    "        \n",
    "        scores[test_rows] = fold_scores\n",
    "        \n",
    "    return scores\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " + Dataset scoring 0 of 5\n",
      " - Processing fold 0 of 2\n",
      " - Processing fold 1 of 2\n",
      " + Dataset scoring 1 of 5\n",
      " - Processing fold 0 of 2\n",
      " - Processing fold 1 of 2\n",
      " + Dataset scoring 2 of 5\n",
      " - Processing fold 0 of 2\n",
      " - Processing fold 1 of 2\n",
      " + Dataset scoring 3 of 5\n",
      " - Processing fold 0 of 2\n",
      " - Processing fold 1 of 2\n",
      " + Dataset scoring 4 of 5\n",
      " - Processing fold 0 of 2\n",
      " - Processing fold 1 of 2\n",
      "-750.202\n"
     ]
    }
   ],
   "source": [
    "L = 5\n",
    "scores = np.empty( (dataset.n_instances, L), dtype=np.float32)\n",
    "for l in range(5):\n",
    "    print (\" + Dataset scoring\", l, \"of\", L)\n",
    "    scores[:,l] = kfold_scoring(dataset, 2, algo=lgbm_algo)\n",
    "\n",
    "print (scores.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
